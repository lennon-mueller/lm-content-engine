# Course 4: Deep Learning and Gen AI Foundations

## Course Purpose
Introduce learners to neural network fundamentals and generative AI concepts while emphasizing responsible usage of Google tools and APIs.

## Target Skills
- Build and train simple feedforward and convolutional networks using TensorFlow/Keras in Colab.
- Explain transformer basics and generative model capabilities/limitations in plain language.
- Use Vertex AI PaLM API responsibly for text generation, summarization, and prompt design.
- Evaluate generative outputs for quality, safety, and bias with transparent criteria.

## Course Architecture (4 modules)
1. **Neural Network Building Blocks**  
   - Why: Neural nets power many modern products; hook with everyday AI examples.  
   - What: Neurons, layers, activation functions, loss/optimization basics.  
   - How: Guided Keras notebook for MNIST-like dataset with clear commentary.  
   - Apply: Learners modify architecture and observe performance shifts.  
   - Assess: Auto-graded notebook tests plus quiz variations.  
   - Playful context: Dolphin auditory cortex pattern detection as a neural metaphor.

2. **Convolutional Networks and Vision Tasks**  
   - Why: Vision models drive safety and accessibility features; hook on inclusive design.  
   - What: Convolutions, pooling, transfer learning basics.  
   - How: Notebook fine-tuning a small vision model with TensorFlow Hub.  
   - Apply: Learners adjust augmentations and evaluate confusion matrices.  
   - Assess: Quiz with scenario feedback; short reflection on data bias.  
   - Playful context: Dolphin echolocation maps as an analogy for feature maps.

3. **Transformers and Prompt Design**  
   - Why: Transformers enable state-of-the-art language and multimodal models; hook on productivity gains.  
   - What: Attention mechanism intuition, tokenization, safety filters.  
   - How: Labs using Vertex AI PaLM API for controlled generation; prompt engineering patterns.  
   - Apply: Learners design prompts for summarization and fact-check using retrieval hints.  
   - Assess: Graded quiz referencing review resources; rubric-led prompt critique.  
   - Playful context: Dolphin call-and-response patterns to illustrate attention.

4. **Evaluating and Safeguarding Generative Models**  
   - Why: Safety and trust are critical to ship responsibly.  
   - What: Evaluation dimensions (accuracy, toxicity, bias), red teaming basics, content filters.  
   - How: Hands-on safety evaluation checklist applied to generated outputs.  
   - Apply: Learners log evaluation results and mitigation steps in a model card addendum.  
   - Assess: Peer review plus quiz with variations; references to review items only.  
   - Playful context: Dolphin pod safety protocols as a metaphor for guardrails.

## Assessments and Practice
- Balanced mix of quizzes, auto-graded labs, and peer-reviewed prompt critiques.
- Clear WWHAA per module, with hooks at 5th-grade readability for openings.

## Tools and Logistics
- Tools: Colab with TensorFlow/Keras, TensorFlow Hub, Vertex AI PaLM API.  
- Accessibility: captions, alt text, inclusive examples, low-bandwidth notebook options.
